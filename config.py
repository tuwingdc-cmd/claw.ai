"""
Configuration & Provider Registry
All providers, models, and defaults in one place
â€” Verified against official docs & manual API testing: Feb 27, 2026 â€”

CHANGELOG:
- [Cerebras]     HAPUS: llama-3.3-70b & qwen-3-32b (DEPRECATED 16 Feb 2026)
                 HAPUS: gpt-oss-20b (tidak ada di daftar resmi)
- [Groq]         FIX: compound-beta â†’ groq/compound (sesuai test)
                 HAPUS: llama3-groq-*-tool-use, qwen-qwq-32b, deepseek-r1-distill
                        (tidak ada di list model test)
                 TAMBAH: allam-2-7b, kimi-k2-instruct, llama-guard-4-12b
- [OpenRouter]   REVAMP: Tambah semua :free dari test, tambah premium picks
                 TAMBAH: gpt-oss-120b:free, gpt-oss-20b:free,
                         qwen3-coder:free, gemma-3n, liquid, cognitivecomputations,
                         arcee-ai, stepfun, upstage, + premium flagships
- [Gemini]       TAMBAH: gemini-3-pro, gemini-3-flash, gemini-3.1-pro,
                         gemma-3n-e4b-it, gemma-3n-e2b-it dari test
- [Cloudflare]   EXPAND: tambah 15+ model dari test (qwen3-30b, qwq-32b,
                         gpt-oss-120b/20b, granite, flux, whisper, dll)
- [HuggingFace]  EXPAND: tambah model dari test (DeepSeek-V3.2, Qwen3.5,
                         gemma-3-27b, gpt-oss, FLUX, whisper, dll)
- [Cohere]       EXPAND: tambah embed, rerank, aya models dari test
- [SiliconFlow]  EXPAND: tambah 30+ model dari test (GLM-5, ERNIE, Kimi,
                         Qwen3-Coder, VL models, video gen, TTS, dll)
- [SambaNova]    UPDATE: sesuaikan 18 model dari test (tambah V3.1, V3.2,
                         MiniMax-M2.5, ALLaM, Swallow, hapus yang tidak ada)
- [NVIDIA]       EXPAND: tambah 30+ model dari test (Nemotron Ultra 253B,
                         Mistral Large 675B, Qwen3.5-397B, Kimi-K2.5, dll)
- [Mistral]      BARU: provider baru, 15 model dari test
- [OpenAI]       BARU: provider premium, 10 model
- [Anthropic]    BARU: provider premium, 5 model
- [xAI]          BARU: provider premium, 6 model
- [Pollinations] UPDATE: sesuaikan dari test (hapus chickytutor/legacy,
                         tambah qwen-character)
- [Routeway]     OK â€” tidak ada perubahan
- [Puter]        OK â€” tidak ada perubahan
- [MLVOCA]       OK â€” tidak ada perubahan

LEGEND:
ğŸ†“ = Free model (no cost)
ğŸ’ = Premium / Paid only
âš ï¸ = Limited free tier (ketat / credit-based)
â­ = Support Tool Calling (web search, dll)
ğŸ”¥ = Recommended (fitur lengkap / performa bagus)
ğŸ‘ï¸ = Vision (bisa lihat gambar)
ğŸ§  = Reasoning mode
ğŸ” = Search/Grounding built-in
"""

import os
from dotenv import load_dotenv
from typing import Dict, List, Optional
from dataclasses import dataclass, field

load_dotenv()

# ============================================================
# ENVIRONMENT VARIABLES
# ============================================================

DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
DISCORD_PREFIX = os.getenv("DISCORD_PREFIX", "!")

DATABASE_URL = os.getenv("DATABASE_URL")
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

# ============================================================
# PROVIDER API KEYS
# ============================================================

API_KEYS = {
    "groq":               os.getenv("GROQ_API_KEY"),
    "openweathermap":     os.getenv("OPENWEATHERMAP_API_KEY"),
    "openrouter":         os.getenv("OPENROUTER_API_KEY"),
    "pollinations":       os.getenv("POLLINATIONS_API_KEY"),
    "gemini":             os.getenv("GEMINI_API_KEY"),
    "cerebras":           os.getenv("CEREBRAS_API_KEY"),
    "sambanova":          os.getenv("SAMBANOVA_API_KEY"),
    "cloudflare":         os.getenv("CLOUDFLARE_API_TOKEN"),
    "cloudflare_account": os.getenv("CLOUDFLARE_ACCOUNT_ID"),
    "huggingface":        os.getenv("HUGGINGFACE_TOKEN"),
    "cohere":             os.getenv("COHERE_API_KEY"),
    "siliconflow":        os.getenv("SILICONFLOW_API_KEY"),
    "routeway":           os.getenv("ROUTEWAY_API_KEY"),
    "nvidia":             os.getenv("NVIDIA_API_KEY"),
    "mistral":            os.getenv("MISTRAL_API_KEY"),
    "openai":             os.getenv("OPENAI_API_KEY"),
    "anthropic":          os.getenv("ANTHROPIC_API_KEY"),
    "xai":                os.getenv("XAI_API_KEY"),
    "tavily":             os.getenv("TAVILY_API_KEY"),
    "brave":              os.getenv("BRAVE_API_KEY"),
    "serper":             os.getenv("SERPER_API_KEY"),
    "puter_api_key":      os.getenv("PUTER_API_KEY"),
}

# ============================================================
# DEFAULTS
# ============================================================

DEFAULTS = {
    "provider":      os.getenv("DEFAULT_PROVIDER", "groq"),
    "model":         os.getenv("DEFAULT_MODEL", "llama-3.3-70b-versatile"),
    "mode":          "normal",
    "auto_chat":     False,
    "auto_detect":   False,
    "search_engine": "duckduckgo",
}

# ============================================================
# PROVIDER REGISTRY
# ============================================================

@dataclass
class Model:
    id: str
    name: str
    modes: List[str] = field(default_factory=lambda: ["normal"])
    context: int = 8192
    vision: bool = False
    tools: bool = False

@dataclass
class Provider:
    name: str
    endpoint: str
    models: List[Model]
    auth_header: str = "Authorization"
    auth_prefix: str = "Bearer"
    free_tier: bool = True
    rate_limit: str = ""

# ============================================================
# PROVIDER DEFINITIONS â€” UPDATED FEB 27, 2026
# ============================================================

PROVIDERS: Dict[str, Provider] = {

    # ==================== GROQ ====================
    # ğŸ†“ SEMUA MODEL GRATIS â€” No credit card needed
    # Docs: https://console.groq.com/docs/models
    # Rate: ~14,400 req/hari, ~1M token/hari per model
    # Verified: curl api.groq.com/openai/v1/models â€” 20 models
    "groq": Provider(
        name="Groq",
        endpoint="https://api.groq.com/openai/v1/chat/completions",
        rate_limit="30 RPM (70B), 60 RPM (8B) â€” ALL FREE",
        models=[
            # â”€â”€ Compound AI (Web Search built-in) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("groq/compound",      "ğŸ†“ Groq Compound ğŸ”¥ğŸ”â­",     ["normal", "search"], 131072, tools=True),
            Model("groq/compound-mini", "ğŸ†“ Groq Compound Mini ğŸ”â­",  ["normal", "search"], 131072, tools=True),

            # â”€â”€ Production Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("llama-3.3-70b-versatile", "ğŸ†“ Llama 3.3 70B â­",    ["normal"], 131072, tools=True),
            Model("llama-3.1-8b-instant",    "ğŸ†“ Llama 3.1 8B â­",     ["normal"], 131072, tools=True),

            # â”€â”€ GPT-OSS Series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("openai/gpt-oss-120b",          "ğŸ†“ GPT-OSS 120B ğŸ”¥â­ğŸ§ ",  ["normal", "reasoning"], 131072, tools=True),
            Model("openai/gpt-oss-20b",           "ğŸ†“ GPT-OSS 20B â­",        ["normal"],              131072, tools=True),
            Model("openai/gpt-oss-safeguard-20b", "ğŸ†“ GPT-OSS Safeguard 20B", ["normal"],              131072),

            # â”€â”€ Llama 4 (Vision + Reasoning) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("meta-llama/llama-4-maverick-17b-128e-instruct", "ğŸ†“ Llama 4 Maverick ğŸ‘ï¸ğŸ§ â­", ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("meta-llama/llama-4-scout-17b-16e-instruct",     "ğŸ†“ Llama 4 Scout ğŸ‘ï¸â­",      ["normal"],              131072, vision=True, tools=True),

            # â”€â”€ Qwen / Moonshot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("qwen/qwen3-32b",                   "ğŸ†“ Qwen 3 32B ğŸ§ â­",  ["normal", "reasoning"], 131072, tools=True),
            Model("moonshotai/kimi-k2-instruct-0905",  "ğŸ†“ Kimi K2 0905 â­",   ["normal"],              131072, tools=True),
            Model("moonshotai/kimi-k2-instruct",       "ğŸ†“ Kimi K2 â­",        ["normal"],              131072, tools=True),

            # â”€â”€ Arabic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("allam-2-7b", "ğŸ†“ ALLaM 2 7B", ["normal"], 8192),

            # â”€â”€ Safety / Guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("meta-llama/llama-guard-4-12b",        "ğŸ†“ Llama Guard 4 12B ğŸ›¡ï¸",   ["normal"], 131072),
            Model("meta-llama/llama-prompt-guard-2-86m",  "ğŸ†“ Prompt Guard 86M ğŸ›¡ï¸",    ["normal"], 131072),
            Model("meta-llama/llama-prompt-guard-2-22m",  "ğŸ†“ Prompt Guard 22M ğŸ›¡ï¸",    ["normal"], 131072),

            # â”€â”€ Audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("whisper-large-v3",       "ğŸ†“ Whisper V3",       ["audio"]),
            Model("whisper-large-v3-turbo", "ğŸ†“ Whisper V3 Turbo", ["audio"]),
        ]
    ),

    # ==================== MISTRAL ====================
    # âš ï¸ FREE EXPERIMENT PLAN â€” 1B tokens/month, no credit card
    # Docs: https://console.mistral.ai/models
    # Verified: curl api.mistral.ai/v1/models â€” 45 models (function_calling)
    "mistral": Provider(
        name="Mistral",
        endpoint="https://api.mistral.ai/v1/chat/completions",
        rate_limit="1B tokens/month FREE (Experiment plan)",
        models=[
            # â”€â”€ Flagship â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("mistral-large-latest",   "âš ï¸ Mistral Large ğŸ”¥â­",       ["normal"], 131072, tools=True),
            Model("mistral-medium-latest",  "âš ï¸ Mistral Medium â­",        ["normal"], 131072, tools=True),
            Model("mistral-small-latest",   "âš ï¸ Mistral Small â­",         ["normal"], 131072, tools=True),

            # â”€â”€ Ministral (Small & Fast) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("ministral-3b-latest",  "âš ï¸ Ministral 3B â­",  ["normal"], 131072, tools=True),
            Model("ministral-8b-latest",  "âš ï¸ Ministral 8B â­",  ["normal"], 131072, tools=True),
            Model("ministral-14b-latest", "âš ï¸ Ministral 14B â­", ["normal"], 131072, tools=True),

            # â”€â”€ Coding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("codestral-latest",       "âš ï¸ Codestral ğŸ’»â­",             ["normal"], 131072, tools=True),
            Model("devstral-medium-latest", "âš ï¸ Devstral Medium ğŸ’»â­",       ["normal"], 131072, tools=True),
            Model("devstral-small-latest",  "âš ï¸ Devstral Small ğŸ’»â­",        ["normal"], 131072, tools=True),

            # â”€â”€ Reasoning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("magistral-medium-latest", "âš ï¸ Magistral Medium ğŸ§ â­", ["normal", "reasoning"], 131072, tools=True),
            Model("magistral-small-latest",  "âš ï¸ Magistral Small ğŸ§ â­",  ["normal", "reasoning"], 131072, tools=True),

            # â”€â”€ Vision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("pixtral-large-latest", "âš ï¸ Pixtral Large ğŸ‘ï¸â­", ["normal"], 131072, vision=True, tools=True),

            # â”€â”€ Audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("voxtral-small-latest", "âš ï¸ Voxtral Small ğŸ”Šâ­", ["normal"], 131072, tools=True),

            # â”€â”€ OCR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("mistral-ocr-latest", "âš ï¸ Mistral OCR ğŸ“„â­", ["normal"], 131072, tools=True),

            # â”€â”€ Legacy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("open-mistral-nemo", "âš ï¸ Mistral Nemo â­", ["normal"], 131072, tools=True),
        ]
    ),

    # ==================== OPENAI ====================
    # ğŸ’ PAID ONLY â€” Production use, credit card required
    # Docs: https://platform.openai.com/docs/models
    # Verified: curl api.openai.com/v1/models
    "openai": Provider(
        name="OpenAI",
        endpoint="https://api.openai.com/v1/chat/completions",
        free_tier=False,
        rate_limit="Paid only â€” varies by tier",
        models=[
            # â”€â”€ GPT-5 Series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gpt-5.2-pro",  "ğŸ’ GPT-5.2 Pro ğŸ”¥â­ğŸ‘ï¸",  ["normal"],    256000, vision=True, tools=True),
            Model("gpt-5.2",      "ğŸ’ GPT-5.2 â­ğŸ‘ï¸",         ["normal"],    256000, vision=True, tools=True),
            Model("gpt-5",        "ğŸ’ GPT-5 â­ğŸ‘ï¸",            ["normal"],    128000, vision=True, tools=True),
            Model("gpt-5-mini",   "ğŸ’ GPT-5 Mini â­ğŸ‘ï¸",       ["normal"],    128000, vision=True, tools=True),
            Model("gpt-5-nano",   "ğŸ’ GPT-5 Nano â­",          ["normal"],    128000, tools=True),

            # â”€â”€ GPT-4.1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gpt-4.1",      "ğŸ’ GPT-4.1 â­ğŸ‘ï¸",      ["normal"], 1000000, vision=True, tools=True),
            Model("gpt-4.1-mini", "ğŸ’ GPT-4.1 Mini â­ğŸ‘ï¸",  ["normal"], 1000000, vision=True, tools=True),
            Model("gpt-4.1-nano", "ğŸ’ GPT-4.1 Nano â­",     ["normal"], 1000000, tools=True),

            # â”€â”€ Reasoning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("o4-mini",  "ğŸ’ o4-mini ğŸ§ â­",  ["reasoning"], 200000, tools=True),
            Model("o3",       "ğŸ’ o3 ğŸ§ â­",       ["reasoning"], 200000, tools=True),
            Model("o3-pro",   "ğŸ’ o3 Pro ğŸ§ ",     ["reasoning"], 200000),

            # â”€â”€ Open Source (gpt-oss) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gpt-oss-120b", "ğŸ’ GPT-OSS 120B ğŸ§ â­", ["normal", "reasoning"], 131072, tools=True),
            Model("gpt-oss-20b",  "ğŸ’ GPT-OSS 20B â­",    ["normal"],              131072, tools=True),
        ]
    ),

    # ==================== ANTHROPIC ====================
    # ğŸ’ PAID ONLY â€” Production use, credit card required
    # Docs: https://docs.anthropic.com/claude/docs/models
    # Endpoint: /v1/messages (NOT OpenAI-compatible)
    "anthropic": Provider(
        name="Anthropic",
        endpoint="https://api.anthropic.com/v1/messages",
        auth_header="x-api-key",
        auth_prefix="",
        free_tier=False,
        rate_limit="Paid only â€” varies by tier",
        models=[
            # â”€â”€ Claude 4.6 (Latest) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("claude-opus-4-6",   "ğŸ’ Claude Opus 4.6 ğŸ”¥â­ğŸ‘ï¸",  ["normal"], 1000000, vision=True, tools=True),
            Model("claude-sonnet-4-6", "ğŸ’ Claude Sonnet 4.6 â­ğŸ‘ï¸",  ["normal"], 1000000, vision=True, tools=True),

            # â”€â”€ Claude 4.5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("claude-opus-4-5",   "ğŸ’ Claude Opus 4.5 â­ğŸ‘ï¸",   ["normal"], 200000, vision=True, tools=True),
            Model("claude-sonnet-4-5", "ğŸ’ Claude Sonnet 4.5 ğŸ§ â­ğŸ‘ï¸",["normal", "reasoning"], 200000, vision=True, tools=True),

            # â”€â”€ Claude 3.5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("claude-3-5-haiku",  "ğŸ’ Claude Haiku 3.5 â­",     ["normal"], 200000, tools=True),
            Model("claude-3-5-sonnet", "ğŸ’ Claude 3.5 Sonnet â­ğŸ‘ï¸", ["normal"], 200000, vision=True, tools=True),
        ]
    ),

    # ==================== XAI (GROK) ====================
    # ğŸ’ PAID ONLY â€” Production use
    # Docs: https://api.x.ai/docs
    # Verified: curl api.x.ai/v1/models
    "xai": Provider(
        name="xAI",
        endpoint="https://api.x.ai/v1/chat/completions",
        free_tier=False,
        rate_limit="Paid only â€” varies by tier",
        models=[
            # â”€â”€ Grok 4 Series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("grok-4-1",       "ğŸ’ Grok 4.1 ğŸ”¥â­",        ["normal"], 2000000, tools=True),
            Model("grok-4-1-fast",  "ğŸ’ Grok 4.1 Fast â­",     ["normal"], 2000000, tools=True),
            Model("grok-4",         "ğŸ’ Grok 4 â­",             ["normal"], 131072,  tools=True),
            Model("grok-code-fast-1","ğŸ’ Grok Code Fast ğŸ’»â­",  ["normal"], 131072,  tools=True),

            # â”€â”€ Grok 3 Series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("grok-3",       "ğŸ’ Grok 3 â­",      ["normal"], 131072, tools=True),
            Model("grok-3-mini",  "ğŸ’ Grok 3 Mini ğŸ§ ", ["reasoning"], 131072),
        ]
    ),

    # ==================== OPENROUTER ====================
    # Docs: https://openrouter.ai/models
    # Rate: 20 RPM, 200 RPD (free tier)
    # Verified: curl openrouter.ai/api/v1/models â€” 250+ models
    "openrouter": Provider(
        name="OpenRouter",
        endpoint="https://openrouter.ai/api/v1/chat/completions",
        rate_limit="20 RPM, 200 RPD (free models)",
        models=[
            # â”€â”€ Auto Routers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("openrouter/free",          "ğŸ†“ Auto Router ğŸ”¥â­ğŸ‘ï¸ğŸ§ ",  ["normal", "reasoning"], 200000, vision=True, tools=True),
            Model("openrouter/optimus-alpha", "ğŸ†“ Optimus Alpha ğŸ”¥â­",     ["normal"],              1000000, tools=True),
            Model("openrouter/quasar-alpha",  "ğŸ†“ Quasar Alpha â­",        ["normal"],              1000000, tools=True),

            # â”€â”€ FREE: OpenAI OSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("openai/gpt-oss-120b:free", "ğŸ†“ GPT-OSS 120B ğŸ”¥â­ğŸ§ ",  ["normal", "reasoning"], 131072, tools=True),
            Model("openai/gpt-oss-20b:free",  "ğŸ†“ GPT-OSS 20B â­",        ["normal"],              131072, tools=True),

            # â”€â”€ FREE: Google â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("google/gemma-3-27b-it:free",  "ğŸ†“ Gemma 3 27B â­",     ["normal"], 131072, tools=True),
            Model("google/gemma-3-12b-it:free",  "ğŸ†“ Gemma 3 12B",        ["normal"], 131072),
            Model("google/gemma-3-4b-it:free",   "ğŸ†“ Gemma 3 4B",         ["normal"], 131072),
            Model("google/gemma-3n-e4b-it:free", "ğŸ†“ Gemma 3n E4B",       ["normal"], 131072),
            Model("google/gemma-3n-e2b-it:free", "ğŸ†“ Gemma 3n E2B",       ["normal"], 131072),

            # â”€â”€ FREE: Meta Llama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("meta-llama/llama-4-maverick:free",        "ğŸ†“ Llama 4 Maverick â­ğŸ‘ï¸ğŸ§ ", ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("meta-llama/llama-4-scout:free",           "ğŸ†“ Llama 4 Scout â­ğŸ‘ï¸ğŸ§ ",    ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("meta-llama/llama-3.3-70b-instruct:free",  "ğŸ†“ Llama 3.3 70B â­",         ["normal"],              131072, tools=True),
            Model("meta-llama/llama-3.2-3b-instruct:free",   "ğŸ†“ Llama 3.2 3B",             ["normal"],              131072),

            # â”€â”€ FREE: DeepSeek â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("deepseek/deepseek-chat-v3-0324:free", "ğŸ†“ DeepSeek Chat V3 â­", ["normal"],    64000, tools=True),
            Model("deepseek/deepseek-r1:free",           "ğŸ†“ DeepSeek R1 ğŸ§ ",      ["reasoning"], 64000),
            Model("deepseek/deepseek-r1-zero:free",      "ğŸ†“ DeepSeek R1 Zero ğŸ§ ", ["reasoning"], 64000),

            # â”€â”€ FREE: Qwen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("qwen/qwen3-coder:free",   "ğŸ†“ Qwen3 Coder 480B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 262144, tools=True),
            Model("qwen/qwen3-4b:free",      "ğŸ†“ Qwen3 4B",                 ["normal"],              32768),
            Model("qwen/qwen3-next-80b-a3b-instruct:free", "ğŸ†“ Qwen3 Next 80B", ["normal"],          131072),

            # â”€â”€ FREE: Mistral â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("mistralai/mistral-small-3.1-24b-instruct:free", "ğŸ†“ Mistral Small 3.1 â­", ["normal"], 32768, tools=True),

            # â”€â”€ FREE: NVIDIA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("nvidia/nemotron-3-nano-30b-a3b:free",        "ğŸ†“ Nemotron 3 Nano 30B â­",  ["normal"], 256000, tools=True),
            Model("nvidia/llama-3.1-nemotron-nano-8b-v1:free",  "ğŸ†“ Nemotron Nano 8B â­",     ["normal"], 131072, tools=True),
            Model("nvidia/nemotron-nano-12b-v2-vl:free",        "ğŸ†“ Nemotron 12B VL ğŸ‘ï¸",     ["normal"], 128000, vision=True),
            Model("nvidia/nemotron-nano-9b-v2:free",            "ğŸ†“ Nemotron Nano 9B",         ["normal"], 131072),

            # â”€â”€ FREE: Others â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("nousresearch/hermes-3-llama-3.1-405b:free",  "ğŸ†“ Hermes 3 405B ğŸ”¥",    ["normal"], 131072),
            Model("z-ai/glm-4.5-air:free",                     "ğŸ†“ GLM 4.5 Air â­ğŸ§ ",    ["normal", "reasoning"], 128000, tools=True),
            Model("stepfun/step-3.5-flash:free",                "ğŸ†“ Step 3.5 Flash â­ğŸ§ ", ["normal", "reasoning"], 256000, tools=True),
            Model("upstage/solar-pro-3:free",                   "ğŸ†“ Solar Pro 3",          ["normal"], 131072),
            Model("minimax/minimax-m2.1:free",                  "ğŸ†“ MiniMax M2.1 â­",     ["normal"], 1000000, tools=True),
            Model("arcee-ai/trinity-large-preview:free",        "ğŸ†“ Trinity Large â­",    ["normal"], 128000, tools=True),
            Model("arcee-ai/trinity-mini:free",                 "ğŸ†“ Trinity Mini",         ["normal"], 128000),
            Model("liquid/lfm-2.5-1.2b-thinking:free",          "ğŸ†“ LFM Thinking ğŸ§ ",    ["reasoning"], 32768),
            Model("liquid/lfm-2.5-1.2b-instruct:free",          "ğŸ†“ LFM Instruct",        ["normal"], 32768),
            Model("cognitivecomputations/dolphin-mistral-24b-venice-edition:free", "ğŸ†“ Dolphin 24B ğŸ”“", ["normal"], 32768),
            Model("moonshotai/kimi-vl-a3b-thinking:free",       "ğŸ†“ Kimi VL Thinking ğŸ‘ï¸ğŸ§ ", ["reasoning"], 128000, vision=True),
            Model("nousresearch/deephermes-3-llama-3-8b-preview:free", "ğŸ†“ DeepHermes 3 8B", ["normal"], 131072),

            # â”€â”€ PREMIUM: Flagships â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("openai/gpt-5.2-pro",          "ğŸ’ GPT-5.2 Pro â­ğŸ‘ï¸",       ["normal"],              256000, vision=True, tools=True),
            Model("openai/gpt-5",                "ğŸ’ GPT-5 â­ğŸ‘ï¸",             ["normal"],              128000, vision=True, tools=True),
            Model("anthropic/claude-opus-4.6",   "ğŸ’ Claude Opus 4.6 â­ğŸ‘ï¸",   ["normal"],              1000000, vision=True, tools=True),
            Model("anthropic/claude-sonnet-4.6", "ğŸ’ Claude Sonnet 4.6 â­ğŸ‘ï¸", ["normal"],              1000000, vision=True, tools=True),
            Model("anthropic/claude-sonnet-4.5", "ğŸ’ Claude Sonnet 4.5 ğŸ§ ğŸ‘ï¸", ["normal", "reasoning"], 200000, vision=True),
            Model("google/gemini-3-pro-preview", "ğŸ’ Gemini 3 Pro ğŸ‘ï¸ğŸ§ â­",   ["normal", "reasoning"], 1000000, vision=True, tools=True),
            Model("google/gemini-2.5-pro",       "ğŸ’ Gemini 2.5 Pro ğŸ§ â­",    ["normal", "reasoning"], 1000000, tools=True),
            Model("x-ai/grok-4.1-fast",         "ğŸ’ Grok 4.1 Fast â­",        ["normal"],              2000000, tools=True),
            Model("x-ai/grok-4",                "ğŸ’ Grok 4 â­",               ["normal"],              131072,  tools=True),
            Model("deepseek/deepseek-v3.2",     "ğŸ’ DeepSeek V3.2 â­",        ["normal"],              128000, tools=True),
            Model("moonshotai/kimi-k2.5",       "ğŸ’ Kimi K2.5 ğŸ‘ï¸â­ğŸ§ ",       ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("minimax/minimax-m2.5",       "ğŸ’ MiniMax M2.5 â­",         ["normal"],              1000000, tools=True),
        ]
    ),

    # ==================== GEMINI ====================
    # ğŸ†“ SEMUA GRATIS via Google AI Studio â€” reduced quotas since Dec 2025
    # Docs: https://ai.google.dev/gemini-api/docs/models
    # Verified: curl generativelanguage.googleapis.com â€” 45+ models
    "gemini": Provider(
        name="Google Gemini",
        endpoint="https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent",
        auth_header="x-goog-api-key",
        auth_prefix="",
        rate_limit="15 RPM, 1500 RPD (free tier)",
        models=[
            # â”€â”€ Gemini 3.x Preview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gemini-3.1-pro-preview",  "ğŸ†“ Gemini 3.1 Pro Preview ğŸ”¥ğŸ‘ï¸ğŸ§ â­", ["normal", "reasoning"], 1048576, vision=True, tools=True),
            Model("gemini-3-pro-preview",    "ğŸ†“ Gemini 3 Pro Preview ğŸ‘ï¸ğŸ§ â­",     ["normal", "reasoning"], 1048576, vision=True, tools=True),
            Model("gemini-3-flash-preview",  "ğŸ†“ Gemini 3 Flash Preview ğŸ‘ï¸â­",     ["normal"],              1048576, vision=True, tools=True),

            # â”€â”€ Gemini 2.5 (Stable) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gemini-2.5-pro",        "ğŸ†“ Gemini 2.5 Pro ğŸ”¥ğŸ§ â­",    ["normal", "reasoning"], 1048576, tools=True),
            Model("gemini-2.5-flash",      "ğŸ†“ Gemini 2.5 Flash ğŸ§ â­",    ["normal", "reasoning"], 1048576, tools=True),
            Model("gemini-2.5-flash-lite", "ğŸ†“ Gemini 2.5 Flash Lite â­",  ["normal"],              1048576, tools=True),

            # â”€â”€ Gemini 2.0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gemini-2.0-flash",      "ğŸ†“ Gemini 2.0 Flash ğŸ‘ï¸â­",    ["normal"], 1048576, vision=True, tools=True),
            Model("gemini-2.0-flash-lite", "ğŸ†“ Gemini 2.0 Flash Lite",     ["normal"], 1048576),

            # â”€â”€ Gemma Open Source â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gemma-3-27b-it",   "ğŸ†“ Gemma 3 27B â­",  ["normal"], 131072, tools=True),
            Model("gemma-3-12b-it",   "ğŸ†“ Gemma 3 12B",     ["normal"], 131072),
            Model("gemma-3-4b-it",    "ğŸ†“ Gemma 3 4B",      ["normal"], 131072),
            Model("gemma-3n-e4b-it",  "ğŸ†“ Gemma 3n E4B ğŸ“±", ["normal"], 131072),
            Model("gemma-3n-e2b-it",  "ğŸ†“ Gemma 3n E2B ğŸ“±", ["normal"], 131072),
        ]
    ),

    # ==================== CEREBRAS ====================
    # âš ï¸ 30 RPM, 1M tokens/day FREE
    # Docs: https://inference-docs.cerebras.ai/introduction
    # Note: llama-3.3-70b & qwen-3-32b DEPRECATED 16 Feb 2026
    "cerebras": Provider(
        name="Cerebras",
        endpoint="https://api.cerebras.ai/v1/chat/completions",
        rate_limit="30 RPM, 1M tokens/day (free tier)",
        models=[
            Model("zai-glm-4.7",                    "âš ï¸ Z.ai GLM 4.7 ğŸ”¥â­ğŸ§ ",       ["normal", "reasoning"], 128000, tools=True),
            Model("gpt-oss-120b",                   "âš ï¸ GPT-OSS 120B ğŸ”¥â­ğŸ§ ",       ["normal", "reasoning"], 131072, tools=True),
            Model("llama3.1-8b",                    "âš ï¸ Llama 3.1 8B â­",            ["normal"],              128000, tools=True),
            Model("qwen-3-235b-a22b-instruct-2507", "âš ï¸ Qwen 3 235B Instruct â­ğŸ§ ", ["normal", "reasoning"], 262144, tools=True),
        ]
    ),

    # ==================== SAMBANOVA ====================
    # âš ï¸ $5 FREE CREDIT (expire 30 hari), then free tier ketat
    # Docs: https://community.sambanova.ai/t/supported-models
    # Verified: curl api.sambanova.ai/v1/models â€” 18 models
    "sambanova": Provider(
        name="SambaNova",
        endpoint="https://api.sambanova.ai/v1/chat/completions",
        rate_limit="$5 free credit (30 days), then rate-limited free tier",
        models=[
            # â”€â”€ Meta Llama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Meta-Llama-3.1-8B-Instruct",           "âš ï¸ Llama 3.1 8B â­",       ["normal"], 8192,   tools=True),
            Model("Meta-Llama-3.3-70B-Instruct",          "âš ï¸ Llama 3.3 70B â­",      ["normal"], 131072, tools=True),
            Model("Llama-4-Maverick-17B-128E-Instruct",   "âš ï¸ Llama 4 Maverick â­ğŸ‘ï¸", ["normal"], 131072, vision=True, tools=True),
            Model("Llama-3.3-Swallow-70B-Instruct-v0.4",  "âš ï¸ Llama Swallow 70B",     ["normal"], 131072),

            # â”€â”€ DeepSeek â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("DeepSeek-R1-0528",             "âš ï¸ DeepSeek R1 0528 ğŸ§ ",       ["reasoning"],  16384),
            Model("DeepSeek-R1-Distill-Llama-70B","âš ï¸ DeepSeek R1 Distill 70B ğŸ§ ",["reasoning"],  131072),
            Model("DeepSeek-V3-0324",             "âš ï¸ DeepSeek V3 0324 â­",       ["normal"],     8192,   tools=True),
            Model("DeepSeek-V3.1",                "âš ï¸ DeepSeek V3.1 â­",          ["normal"],     8192,   tools=True),
            Model("DeepSeek-V3.1-Terminus",       "âš ï¸ DeepSeek V3.1 Terminus â­", ["normal"],     8192,   tools=True),
            Model("DeepSeek-V3.1-cb",             "âš ï¸ DeepSeek V3.1 CB",          ["normal"],     8192),
            Model("DeepSeek-V3.2",                "âš ï¸ DeepSeek V3.2 ğŸ”¥â­",        ["normal"],     8192,   tools=True),

            # â”€â”€ Qwen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen3-235B", "âš ï¸ Qwen 3 235B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 32768, tools=True),
            Model("Qwen3-32B",  "âš ï¸ Qwen 3 32B â­ğŸ§ ",    ["normal", "reasoning"], 32768, tools=True),

            # â”€â”€ GPT-OSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gpt-oss-120b", "âš ï¸ GPT-OSS 120B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 131072, tools=True),

            # â”€â”€ Others â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("MiniMax-M2.5",              "âš ï¸ MiniMax M2.5 â­",  ["normal"], 197000, tools=True),
            Model("ALLaM-7B-Instruct-preview", "âš ï¸ ALLaM 7B",        ["normal"], 8192),

            # â”€â”€ Audio / Embedding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Whisper-Large-v3",        "âš ï¸ Whisper V3",        ["audio"]),
            Model("E5-Mistral-7B-Instruct",  "âš ï¸ E5 Mistral 7B ğŸ“Š", ["normal"]),
        ]
    ),

    # ==================== NVIDIA NIM ====================
    # âš ï¸ FREE TIER â€” unlimited prototyping via hosted DGX Cloud
    # Docs: https://build.nvidia.com/explore/discover
    # Verified: curl integrate.api.nvidia.com/v1/models â€” 160+ models
    "nvidia": Provider(
        name="NVIDIA NIM",
        endpoint="https://integrate.api.nvidia.com/v1/chat/completions",
        rate_limit="Free tier (unlimited prototyping, rate-limited)",
        models=[
            # â”€â”€ GPT-OSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("openai/gpt-oss-120b", "âš ï¸ GPT-OSS 120B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 131072, tools=True),
            Model("openai/gpt-oss-20b",  "âš ï¸ GPT-OSS 20B â­",       ["normal"],              131072, tools=True),

            # â”€â”€ NVIDIA Nemotron â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("nvidia/llama-3.1-nemotron-ultra-253b-v1",  "âš ï¸ Nemotron Ultra 253B ğŸ”¥â­ğŸ§ ",   ["normal", "reasoning"], 131072, tools=True),
            Model("nvidia/llama-3.3-nemotron-super-49b-v1",   "âš ï¸ Nemotron Super 49B ğŸ”¥â­ğŸ§ ",    ["normal", "reasoning"], 131072, tools=True),
            Model("nvidia/llama-3.3-nemotron-super-49b-v1.5", "âš ï¸ Nemotron Super 49B v1.5 â­ğŸ§ ", ["normal", "reasoning"], 131072, tools=True),
            Model("nvidia/llama-3.1-nemotron-nano-8b-v1",     "âš ï¸ Nemotron Nano 8B â­ğŸ§ ",        ["normal", "reasoning"], 131072, tools=True),
            Model("nvidia/llama-3.1-nemotron-70b-instruct",   "âš ï¸ Nemotron 70B â­",               ["normal"],              131072, tools=True),
            Model("nvidia/nemotron-nano-12b-v2-vl",           "âš ï¸ Nemotron 12B VL ğŸ‘ï¸ğŸ§ ",        ["normal", "reasoning"], 128000, vision=True),
            Model("nvidia/nvidia-nemotron-nano-9b-v2",        "âš ï¸ Nemotron 9B v2",                ["normal"],              131072),
            Model("nvidia/nemotron-3-nano-30b-a3b",           "âš ï¸ Nemotron 3 Nano 30B â­",        ["normal"],              256000, tools=True),

            # â”€â”€ Qwen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("qwen/qwen3-235b-a22b",                "âš ï¸ Qwen 3 235B ğŸ”¥â­ğŸ§ ",      ["normal", "reasoning"], 131072, tools=True),
            Model("qwen/qwen3.5-397b-a17b",              "âš ï¸ Qwen 3.5 397B ğŸ”¥â­",       ["normal"],              131072, tools=True),
            Model("qwen/qwen3-coder-480b-a35b-instruct", "âš ï¸ Qwen 3 Coder 480B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 262144, tools=True),
            Model("qwen/qwen3-next-80b-a3b-instruct",    "âš ï¸ Qwen 3 Next 80B â­",        ["normal"],              131072, tools=True),
            Model("qwen/qwq-32b",                        "âš ï¸ QwQ 32B ğŸ§ â­",              ["reasoning"],           40960,  tools=True),
            Model("qwen/qwen2.5-coder-32b-instruct",     "âš ï¸ Qwen 2.5 Coder 32B",        ["normal"],              32768),

            # â”€â”€ DeepSeek â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("deepseek-ai/deepseek-v3.2",          "âš ï¸ DeepSeek V3.2 ğŸ”¥â­",     ["normal"],    131072, tools=True),
            Model("deepseek-ai/deepseek-v3.1",          "âš ï¸ DeepSeek V3.1 â­",        ["normal"],    131072, tools=True),
            Model("deepseek-ai/deepseek-v3.1-terminus",  "âš ï¸ DeepSeek V3.1 Terminus â­",["normal"],   131072, tools=True),
            Model("deepseek-ai/deepseek-r1-distill-qwen-32b", "âš ï¸ DeepSeek R1 32B ğŸ§ ", ["reasoning"], 32768),

            # â”€â”€ Meta Llama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("meta/llama-4-maverick-17b-128e-instruct", "âš ï¸ Llama 4 Maverick ğŸ‘ï¸â­ğŸ§ ", ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("meta/llama-4-scout-17b-16e-instruct",     "âš ï¸ Llama 4 Scout ğŸ‘ï¸â­",      ["normal"],              131072, vision=True, tools=True),
            Model("meta/llama-3.3-70b-instruct",             "âš ï¸ Llama 3.3 70B â­",          ["normal"],              131072, tools=True),
            Model("meta/llama-3.1-405b-instruct",            "âš ï¸ Llama 3.1 405B ğŸ”¥â­",       ["normal"],              131072, tools=True),
            Model("meta/llama-3.1-70b-instruct",             "âš ï¸ Llama 3.1 70B â­",          ["normal"],              131072, tools=True),
            Model("meta/llama-3.1-8b-instruct",              "âš ï¸ Llama 3.1 8B â­",           ["normal"],              131072, tools=True),

            # â”€â”€ Mistral â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("mistralai/mistral-large-3-675b-instruct-2512", "âš ï¸ Mistral Large 675B ğŸ”¥â­", ["normal"], 131072, tools=True),
            Model("mistralai/mistral-medium-3-instruct",          "âš ï¸ Mistral Medium 3 â­",      ["normal"], 131072, tools=True),
            Model("mistralai/mistral-small-3.1-24b-instruct-2503","âš ï¸ Mistral Small 3.1 â­",     ["normal"], 131072, tools=True),
            Model("mistralai/mixtral-8x7b-instruct-v0.1",        "âš ï¸ Mixtral 8x7B â­",          ["normal"], 32768,  tools=True),

            # â”€â”€ Moonshot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("moonshotai/kimi-k2.5",              "âš ï¸ Kimi K2.5 ğŸ‘ï¸â­ğŸ§ ",    ["normal", "reasoning"], 131072, vision=True, tools=True),
            Model("moonshotai/kimi-k2-instruct",       "âš ï¸ Kimi K2 â­",           ["normal"],              131072, tools=True),
            Model("moonshotai/kimi-k2-instruct-0905",  "âš ï¸ Kimi K2 0905 â­",      ["normal"],              131072, tools=True),

            # â”€â”€ MiniMax â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("minimaxai/minimax-m2.5", "âš ï¸ MiniMax M2.5 ğŸ”¥â­", ["normal"], 1048576, tools=True),

            # â”€â”€ GLM / StepFun / Others â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("z-ai/glm5",              "âš ï¸ GLM-5 â­",          ["normal"], 128000, tools=True),
            Model("z-ai/glm4.7",            "âš ï¸ GLM-4.7 â­",        ["normal"], 128000, tools=True),
            Model("stepfun-ai/step-3.5-flash","âš ï¸ Step 3.5 Flash â­", ["normal"], 256000, tools=True),

            # â”€â”€ Google Gemma â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("google/gemma-3-27b-it",  "âš ï¸ Gemma 3 27B",  ["normal"], 131072),
            Model("google/gemma-3n-e4b-it", "âš ï¸ Gemma 3n E4B", ["normal"], 131072),
        ]
    ),

    # ==================== POLLINATIONS ====================
    # ğŸ†“ No signup needed, $1.5/week free credits
    # Verified: curl gen.pollinations.ai/models â€” 26 models
    "pollinations": Provider(
        name="Pollinations",
        endpoint="https://gen.pollinations.ai/v1/chat/completions",
        auth_header="Authorization",
        auth_prefix="Bearer",
        rate_limit="1/15s (anon), unlimited (sk_)",
        models=[
            # â”€â”€ ğŸ†“ Free Tier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("qwen-safety",  "ğŸ†“ Qwen3Guard 8B",              ["normal"]),
            Model("nova-fast",    "ğŸ†“ Amazon Nova Micro",           ["normal"]),
            Model("openai-fast",  "ğŸ†“ OpenAI GPT-5 Nano ğŸ‘ï¸",     ["normal"], vision=True),
            Model("gemini-fast",  "ğŸ†“ Gemini 2.5 Flash Lite ğŸ‘ï¸",  ["normal"], vision=True),
            Model("qwen-coder",   "ğŸ†“ Qwen3 Coder 30B",            ["normal"]),
            Model("mistral",      "ğŸ†“ Mistral Small 3.2 24B",      ["normal"]),
            Model("qwen-character","ğŸ†“ Qwen Character ğŸ­",         ["normal"]),

            # Mid Tier
            Model("openai",   "ğŸ†“ OpenAI GPT-5 Mini ğŸ‘ï¸",  ["normal"], vision=True),
            Model("deepseek", "ğŸ†“ DeepSeek V3.2",           ["normal"]),
            Model("minimax",  "ğŸ†“ MiniMax M2.1",            ["normal"]),
            Model("kimi",     "ğŸ†“ Kimi K2.5 ğŸ‘ï¸",           ["normal"], vision=True),
            Model("glm",      "ğŸ†“ Z.ai GLM-5",              ["normal"]),

            # Search Built-in
            Model("perplexity-fast", "ğŸ†“ Perplexity Sonar ğŸ”",              ["search"]),
            Model("gemini-search",   "ğŸ†“ Gemini 2.5 Flash Search ğŸ”¥ğŸ”ğŸ‘ï¸", ["search"], vision=True, tools=True),

            # Premium Features
            Model("openai-large",         "ğŸ†“ OpenAI GPT-5.2 ğŸ‘ï¸",         ["normal"],              vision=True),
            Model("perplexity-reasoning", "ğŸ†“ Perplexity Reasoning ğŸ”ğŸ§ ",  ["reasoning", "search"]),
            Model("openai-audio",         "ğŸ†“ GPT-4o Mini Audio ğŸ‘ï¸",      ["normal"],              vision=True),
            Model("midijourney",          "ğŸ†“ MIDIjourney ğŸµ",             ["normal"]),

            # â”€â”€ ğŸ’ PAID ONLY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("grok",          "ğŸ’ xAI Grok 4 Fast",           ["normal"]),
            Model("gemini",        "ğŸ’ Google Gemini 3 Flash ğŸ‘ï¸", ["normal"],              vision=True),
            Model("claude-fast",   "ğŸ’ Claude Haiku 4.5 ğŸ‘ï¸",      ["normal"],              vision=True),
            Model("claude",        "ğŸ’ Claude Sonnet 4.6 ğŸ‘ï¸",     ["normal"],              vision=True),
            Model("claude-large",  "ğŸ’ Claude Opus 4.6 ğŸ‘ï¸",       ["normal"],              vision=True),
            Model("gemini-large",  "ğŸ’ Gemini 3 Pro ğŸ‘ï¸ğŸ§ ",        ["normal", "reasoning"], vision=True),

            # â”€â”€ ğŸ¤– Agents â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("nomnom", "ğŸ†“ NomNom ğŸ”ğŸ§ ",       ["reasoning", "search"]),
            Model("polly",  "ğŸ†“ Polly ğŸ”¥ğŸ”ğŸ‘ï¸ğŸ§ ",  ["normal", "reasoning", "search"], vision=True),
        ]
    ),

    # ==================== CLOUDFLARE ====================
    # âš ï¸ 10K NEURONS/DAY FREE
    # Docs: https://developers.cloudflare.com/workers-ai/models/
    # Verified: curl api.cloudflare.com/.../ai/models/search â€” 70+ models
    "cloudflare": Provider(
        name="Cloudflare",
        endpoint="https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/{model}",
        rate_limit="10K neurons/day (free tier)",
        models=[
            # â”€â”€ LLM Chat + Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/meta/llama-3.3-70b-instruct-fp8-fast",  "âš ï¸ Llama 3.3 70B â­",     ["normal"], 131072, tools=True),
            Model("@cf/meta/llama-3.1-8b-instruct",            "âš ï¸ Llama 3.1 8B â­",      ["normal"], 131072, tools=True),
            Model("@cf/meta/llama-3.1-8b-instruct-fp8",        "âš ï¸ Llama 3.1 8B FP8 â­",  ["normal"], 131072, tools=True),
            Model("@cf/meta/llama-4-scout-17b-16e-instruct",   "âš ï¸ Llama 4 Scout ğŸ§ â­",   ["normal", "reasoning"], 131072, tools=True),
            Model("@cf/mistralai/mistral-small-3.1-24b-instruct","âš ï¸ Mistral Small 3.1 â­", ["normal"], 32768, tools=True),
            Model("@cf/qwen/qwen2.5-coder-32b-instruct",       "âš ï¸ Qwen 2.5 Coder 32B â­",["normal"], 32768, tools=True),
            Model("@cf/qwen/qwen3-30b-a3b-fp8",                "âš ï¸ Qwen 3 30B â­",        ["normal"], 32768, tools=True),
            Model("@cf/zai-org/glm-4.7-flash",                 "âš ï¸ GLM 4.7 Flash â­",     ["normal"], 131072, tools=True),
            Model("@cf/ibm-granite/granite-4.0-h-micro",       "âš ï¸ Granite 4.0 Micro",    ["normal"], 131072),

            # â”€â”€ GPT-OSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/openai/gpt-oss-120b", "âš ï¸ GPT-OSS 120B ğŸ”¥â­ğŸ§ ", ["normal", "reasoning"], 131072, tools=True),
            Model("@cf/openai/gpt-oss-20b",  "âš ï¸ GPT-OSS 20B â­",       ["normal"],              131072, tools=True),

            # â”€â”€ Vision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/meta/llama-3.2-11b-vision-instruct", "âš ï¸ Llama 3.2 Vision ğŸ‘ï¸", ["normal"], 131072, vision=True),
            Model("@cf/llava-hf/llava-1.5-7b-hf",          "âš ï¸ LLaVA 1.5 7B ğŸ‘ï¸",     ["normal"], 4096,   vision=True),

            # â”€â”€ Reasoning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/deepseek-ai/deepseek-r1-distill-qwen-32b", "âš ï¸ DeepSeek R1 32B ğŸ§ ", ["reasoning"], 32768),
            Model("@cf/qwen/qwq-32b",                              "âš ï¸ QwQ 32B ğŸ§ ",         ["reasoning"], 32768),

            # â”€â”€ Smaller Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/google/gemma-3-12b-it",          "âš ï¸ Gemma 3 12B",     ["normal"], 131072),
            Model("@cf/meta/llama-3.2-3b-instruct",     "âš ï¸ Llama 3.2 3B",    ["normal"], 131072),
            Model("@cf/meta/llama-3.2-1b-instruct",     "âš ï¸ Llama 3.2 1B",    ["normal"], 131072),
            Model("@cf/meta/llama-3-8b-instruct",       "âš ï¸ Llama 3 8B â­",   ["normal"], 8192, tools=True),

            # â”€â”€ Audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/openai/whisper-large-v3-turbo", "âš ï¸ Whisper V3 Turbo", ["audio"]),
            Model("@cf/openai/whisper",                "âš ï¸ Whisper",          ["audio"]),
            Model("@cf/deepgram/nova-3",               "âš ï¸ Deepgram Nova 3",  ["audio"]),

            # â”€â”€ Image Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/black-forest-labs/flux-2-dev",       "âš ï¸ FLUX 2 Dev ğŸ¨",    ["normal"]),
            Model("@cf/black-forest-labs/flux-1-schnell",   "âš ï¸ FLUX 1 Schnell ğŸ¨", ["normal"]),

            # â”€â”€ Embedding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("@cf/baai/bge-m3",           "âš ï¸ BGE M3 ğŸ“Š",        ["normal"]),
            Model("@cf/baai/bge-large-en-v1.5","âš ï¸ BGE Large EN ğŸ“Š",  ["normal"]),
        ]
    ),

    # ==================== HUGGINGFACE ====================
    # Mixed: Small models free via Serverless, large need HF credits
    # Docs: https://huggingface.co/docs/api-inference
    # Verified: curl huggingface.co/api/models?inference=warm â€” 50 models
    "huggingface": Provider(
        name="HuggingFace",
        endpoint="https://router.huggingface.co/v1/chat/completions",
        rate_limit="~50 calls/day (free serverless), credit-based (large models)",
        models=[
            # â”€â”€ ğŸ†“ Gratis via Serverless (model kecil) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("mistralai/Mistral-7B-Instruct-v0.3", "ğŸ†“ Mistral 7B",  ["normal"], 32768),
            Model("HuggingFaceH4/zephyr-7b-beta",       "ğŸ†“ Zephyr 7B",   ["normal"], 32768),

            # â”€â”€ ğŸ’ Via Inference Providers (pakai HF credit) â”€â”€â”€â”€â”€â”€
            Model("meta-llama/Llama-3.3-70B-Instruct",     "ğŸ’ Llama 3.3 70B â­",       ["normal"],              131072, tools=True),
            Model("meta-llama/Meta-Llama-3.1-8B-Instruct", "ğŸ’ Llama 3.1 8B",           ["normal"],              131072),
            Model("Qwen/Qwen3-235B-A22B",                  "ğŸ’ Qwen 3 235B ğŸ§ â­",       ["normal", "reasoning"], 131072, tools=True),
            Model("Qwen/Qwen3.5-397B-A17B",                "ğŸ’ Qwen 3.5 397B ğŸ”¥â­",     ["normal"],              131072, tools=True),
            Model("Qwen/Qwen3.5-35B-A3B",                  "ğŸ’ Qwen 3.5 35B",           ["normal"],              131072),
            Model("Qwen/QwQ-32B",                           "ğŸ’ QwQ 32B ğŸ§ ",             ["reasoning"],           32768),
            Model("deepseek-ai/DeepSeek-R1",               "ğŸ’ DeepSeek R1 ğŸ§ ",          ["reasoning"],           131072),
            Model("deepseek-ai/DeepSeek-R1-0528",          "ğŸ’ DeepSeek R1 0528 ğŸ§ ",     ["reasoning"],           131072),
            Model("deepseek-ai/DeepSeek-V3.2",             "ğŸ’ DeepSeek V3.2 â­",        ["normal"],              131072, tools=True),
            Model("deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",   "ğŸ’ DeepSeek R1 7B ğŸ§ ",  ["reasoning"],           32768),
            Model("deepseek-ai/DeepSeek-R1-Distill-Llama-70B", "ğŸ’ DeepSeek R1 70B ğŸ§ ",  ["reasoning"],           131072),
            Model("google/gemma-3-27b-it",                  "ğŸ’ Gemma 3 27B",             ["normal"],              131072),
            Model("openai/gpt-oss-120b",                    "ğŸ’ GPT-OSS 120B ğŸ§ â­",      ["normal", "reasoning"], 131072, tools=True),
            Model("openai/gpt-oss-20b",                     "ğŸ’ GPT-OSS 20B",             ["normal"],              131072),
        ]
    ),

    # ==================== COHERE ====================
    # âš ï¸ 1000 REQ/MONTH FREE (Trial key, no credit card)
    # Docs: https://docs.cohere.com/v2/docs/models
    # Verified: curl api.cohere.com/v1/models â€” 20 models
    "cohere": Provider(
        name="Cohere",
        endpoint="https://api.cohere.ai/v2/chat",
        rate_limit="1000 calls/month (trial key)",
        models=[
            # â”€â”€ Chat + Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("command-a-vision-07-2025",    "âš ï¸ Command A Vision ğŸ”¥ğŸ‘ï¸â­", ["normal"],              256000, vision=True, tools=True),
            Model("command-a-reasoning-08-2025", "âš ï¸ Command A Reasoning ğŸ§ â­", ["normal", "reasoning"], 256000, tools=True),
            Model("command-r-plus-08-2024",      "âš ï¸ Command R+ ğŸ”â­",          ["normal", "search"],    128000, tools=True),
            Model("command-r-08-2024",           "âš ï¸ Command R â­",             ["normal"],              128000, tools=True),
            Model("command-r7b-12-2024",         "âš ï¸ Command R 7B â­",          ["normal"],              128000, tools=True),
            Model("command-r7b-arabic-02-2025",  "âš ï¸ Command R 7B Arabic â­",   ["normal"],              128000, tools=True),

            # â”€â”€ Multilingual (Aya) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("c4ai-aya-vision-8b",    "âš ï¸ Aya Vision 8B ğŸ‘ï¸",   ["normal"], 8192, vision=True),
            Model("c4ai-aya-expanse-32b",  "âš ï¸ Aya Expanse 32B",     ["normal"], 128000),
            Model("c4ai-aya-expanse-8b",   "âš ï¸ Aya Expanse 8B",      ["normal"], 8192),

            # â”€â”€ Embedding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("embed-v4.0",                        "âš ï¸ Embed V4 ğŸ“Š",               ["normal"]),
            Model("embed-english-v3.0",                "âš ï¸ Embed EN V3 ğŸ“Š",             ["normal"]),
            Model("embed-multilingual-v2.0",           "âš ï¸ Embed Multilingual V2 ğŸ“Š",   ["normal"]),
            Model("embed-english-v3.0-image",          "âš ï¸ Embed EN V3 Image ğŸ“Š",       ["normal"]),
            Model("embed-multilingual-light-v3.0-image","âš ï¸ Embed Multi Light Image ğŸ“Š", ["normal"]),

            # â”€â”€ Rerank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("rerank-v4.0-pro",           "âš ï¸ Rerank V4 Pro ğŸ”",        ["normal"]),
            Model("rerank-v4.0-fast",          "âš ï¸ Rerank V4 Fast ğŸ”",       ["normal"]),
            Model("rerank-multilingual-v3.0",  "âš ï¸ Rerank Multi V3 ğŸ”",      ["normal"]),
        ]
    ),

    # ==================== SILICONFLOW ====================
    # Mixed: Some free, most paid (very cheap pricing)
    # Docs: https://docs.siliconflow.cn/en/api-reference
    # âš ï¸ Domain: api.siliconflow.COM (bukan .cn!)
    # Verified: curl api.siliconflow.com/v1/models â€” 90+ models
    "siliconflow": Provider(
        name="SiliconFlow",
        endpoint="https://api.siliconflow.com/v1/chat/completions",
        rate_limit="100 RPD (free models), varies (paid)",
        models=[
            # â”€â”€ ğŸ†“ FREE Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen/Qwen2.5-7B-Instruct",              "ğŸ†“ Qwen 2.5 7B",               ["normal"],    32768),
            Model("Qwen/Qwen2.5-Coder-7B-Instruct",        "ğŸ†“ Qwen 2.5 Coder 7B",         ["normal"],    32768),
            Model("THUDM/GLM-4-9B-0414",                   "ğŸ†“ GLM 4 9B",                   ["normal"],    128000),
            Model("THUDM/GLM-Z1-9B-0414",                  "ğŸ†“ GLM Z1 9B ğŸ§ ",              ["reasoning"], 128000),
            Model("deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",  "ğŸ†“ DeepSeek R1 7B ğŸ§ ",      ["reasoning"], 32768),
            Model("deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "ğŸ†“ DeepSeek R1 14B ğŸ§ ",     ["reasoning"], 32768),
            Model("deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", "ğŸ†“ DeepSeek R1 32B ğŸ§ ",     ["reasoning"], 32768),
            Model("Qwen/QwQ-32B",                           "ğŸ†“ QwQ 32B ğŸ§ ",                ["reasoning"], 32768),
            Model("meta-llama/Meta-Llama-3.1-8B-Instruct",  "ğŸ†“ Llama 3.1 8B",              ["normal"],    131072),

            # â”€â”€ ğŸ’ PAID: Flagship Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("deepseek-ai/DeepSeek-V3.2",          "ğŸ’ DeepSeek V3.2 ğŸ”¥â­",     ["normal"],              164000, tools=True),
            Model("deepseek-ai/DeepSeek-V3.2-Exp",      "ğŸ’ DeepSeek V3.2 Exp â­",   ["normal"],              164000, tools=True),
            Model("deepseek-ai/DeepSeek-V3.1",          "ğŸ’ DeepSeek V3.1 â­",        ["normal"],              164000, tools=True),
            Model("deepseek-ai/DeepSeek-V3.1-Terminus",  "ğŸ’ DeepSeek V3.1 Terminus â­",["normal"],            164000, tools=True),
            Model("deepseek-ai/DeepSeek-V3",            "ğŸ’ DeepSeek V3",              ["normal"],              164000),
            Model("deepseek-ai/DeepSeek-R1",            "ğŸ’ DeepSeek R1 ğŸ§ ",           ["reasoning"],           164000),
            Model("deepseek-ai/DeepSeek-R1-0528",       "ğŸ’ DeepSeek R1 0528 ğŸ§ ",     ["reasoning"],           164000),

            # â”€â”€ ğŸ’ PAID: Qwen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen/Qwen3-235B-A22B-Instruct-2507",  "ğŸ’ Qwen 3 235B ğŸ”¥â­ğŸ§ ",  ["normal", "reasoning"], 262144, tools=True),
            Model("Qwen/Qwen3-235B-A22B-Thinking-2507",  "ğŸ’ Qwen 3 235B Think ğŸ§ ", ["reasoning"],           262144),
            Model("Qwen/Qwen3-Coder-480B-A35B-Instruct", "ğŸ’ Qwen Coder 480B ğŸ”¥â­", ["normal"],              262144, tools=True),
            Model("Qwen/Qwen3-Coder-30B-A3B-Instruct",   "ğŸ’ Qwen Coder 30B â­",    ["normal"],              131072, tools=True),
            Model("Qwen/Qwen3-32B",                      "ğŸ’ Qwen 3 32B ğŸ§ â­",      ["normal", "reasoning"], 32768,  tools=True),
            Model("Qwen/Qwen3-14B",                      "ğŸ’ Qwen 3 14B",            ["normal"],              32768),
            Model("Qwen/Qwen3-8B",                       "ğŸ’ Qwen 3 8B ğŸ§ â­",       ["normal", "reasoning"], 40960,  tools=True),
            Model("Qwen/Qwen3-Next-80B-A3B-Instruct",    "ğŸ’ Qwen 3 Next 80B â­",   ["normal"],              131072, tools=True),
            Model("Qwen/Qwen-Image",                     "ğŸ’ Qwen Image ğŸ¨",         ["normal"]),
            Model("Qwen/Qwen-Image-Edit",                "ğŸ’ Qwen Image Edit ğŸ¨",    ["normal"]),

            # â”€â”€ ğŸ’ PAID: Qwen Vision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen/Qwen3-VL-235B-A22B-Instruct",    "ğŸ’ Qwen VL 235B ğŸ‘ï¸â­",   ["normal"],    262144, vision=True, tools=True),
            Model("Qwen/Qwen3-VL-235B-A22B-Thinking",    "ğŸ’ Qwen VL 235B Think ğŸ‘ï¸ğŸ§ ",["reasoning"], 262144, vision=True),
            Model("Qwen/Qwen3-VL-32B-Instruct",          "ğŸ’ Qwen VL 32B ğŸ‘ï¸",      ["normal"],    131072, vision=True),
            Model("Qwen/Qwen3-VL-8B-Instruct",           "ğŸ’ Qwen VL 8B ğŸ‘ï¸",       ["normal"],    32768,  vision=True),

            # â”€â”€ ğŸ’ PAID: Moonshot / MiniMax / GLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("moonshotai/Kimi-K2.5",          "ğŸ’ Kimi K2.5 ğŸ‘ï¸â­ğŸ§ ",     ["normal", "reasoning"], 262144, vision=True, tools=True),
            Model("moonshotai/Kimi-K2-Instruct",   "ğŸ’ Kimi K2 â­",            ["normal"],              131072, tools=True),
            Model("moonshotai/Kimi-K2-Thinking",   "ğŸ’ Kimi K2 Think ğŸ§ ",      ["reasoning"],           131072),
            Model("MiniMaxAI/MiniMax-M2.5",        "ğŸ’ MiniMax M2.5 â­",       ["normal"],              197000, tools=True),
            Model("MiniMaxAI/MiniMax-M2.1",        "ğŸ’ MiniMax M2.1",          ["normal"],              197000),
            Model("zai-org/GLM-5",                  "ğŸ’ GLM-5 ğŸ”¥â­",            ["normal"],              128000, tools=True),
            Model("zai-org/GLM-4.7",                "ğŸ’ GLM-4.7 â­",            ["normal"],              128000, tools=True),
            Model("zai-org/GLM-4.6V",               "ğŸ’ GLM-4.6V ğŸ‘ï¸",          ["normal"],              128000, vision=True),

            # â”€â”€ ğŸ’ PAID: Baidu / ByteDance / Tencent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("baidu/ERNIE-4.5-300B-A47B",            "ğŸ’ ERNIE 4.5 300B ğŸ”¥â­", ["normal"], 128000, tools=True),
            Model("tencent/Hunyuan-A13B-Instruct",        "ğŸ’ Hunyuan A13B",         ["normal"], 128000),
            Model("ByteDance-Seed/Seed-OSS-36B-Instruct", "ğŸ’ ByteDance Seed 36B",   ["normal"], 131072),

            # â”€â”€ ğŸ’ PAID: Omni (Audio+Vision) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen/Qwen3-Omni-30B-A3B-Instruct", "ğŸ’ Qwen Omni 30B ğŸ‘ï¸ğŸ”Š", ["normal"], 131072, vision=True),

            # â”€â”€ ğŸ’ PAID: Video Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Wan-AI/Wan2.2-T2V-A14B", "ğŸ’ Wan T2V ğŸ¬",  ["normal"]),
            Model("Wan-AI/Wan2.2-I2V-A14B", "ğŸ’ Wan I2V ğŸ¬",  ["normal"]),

            # â”€â”€ ğŸ’ PAID: Image Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("black-forest-labs/FLUX.2-pro",        "ğŸ’ FLUX 2 Pro ğŸ¨",    ["normal"]),
            Model("black-forest-labs/FLUX.1-Kontext-pro","ğŸ’ FLUX Kontext ğŸ¨",  ["normal"]),
            Model("black-forest-labs/FLUX.1-schnell",    "ğŸ’ FLUX Schnell ğŸ¨",  ["normal"]),

            # â”€â”€ ğŸ’ PAID: TTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("fishaudio/fish-speech-1.5",      "ğŸ’ Fish Speech ğŸ”Š",  ["normal"]),
            Model("FunAudioLLM/CosyVoice2-0.5B",   "ğŸ’ CosyVoice ğŸ”Š",   ["normal"]),

            # â”€â”€ ğŸ’ PAID: Embedding & Rerank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("Qwen/Qwen3-Embedding-8B",  "ğŸ’ Qwen Embed 8B ğŸ“Š",   ["normal"]),
            Model("Qwen/Qwen3-Reranker-8B",   "ğŸ’ Qwen Rerank 8B ğŸ”",  ["normal"]),
        ]
    ),

    # ==================== ROUTEWAY ====================
    # âš ï¸ $1 FREE CREDIT saat daftar, 70+ model via unified API
    # Docs: https://routeway.ai/docs
    # Rate: 20 RPM, 200 RPD (free models)
    "routeway": Provider(
        name="Routeway",
        endpoint="https://api.routeway.ai/v1/chat/completions",
        rate_limit="20 RPM, 200 RPD (free models)",
        models=[
            Model("glm-4.6:free",                "ğŸ†“ GLM 4.6 ğŸ”¥â­ğŸ§ ",    ["normal", "reasoning"], 200000, tools=True),
            Model("glm-4.5-air:free",            "ğŸ†“ GLM 4.5 Air",        ["normal"],              131000),
            Model("deepseek-r1:free",            "ğŸ†“ DeepSeek R1 ğŸ§ ",     ["reasoning"],           164000),
            Model("minimax-m2:free",             "ğŸ†“ MiniMax M2",          ["normal"],              197000),
            Model("kimi-k2:free",                "ğŸ†“ Kimi K2 â­",         ["normal"],              262000, tools=True),
            Model("deepseek-v3.1:free",          "ğŸ†“ DeepSeek V3.1 â­",   ["normal"],              131000, tools=True),
            Model("llama-3.3-70b-instruct:free", "ğŸ†“ Llama 3.3 70B â­",   ["normal"],              131000, tools=True),
            Model("mistral-small-3:free",        "ğŸ†“ Mistral Small 3 â­",  ["normal"],              32768,  tools=True),
        ]
    ),

    # ==================== MLVOCA ====================
    # ğŸ†“ No API key required, unlimited, model kecil saja
    "mlvoca": Provider(
        name="MLVOCA",
        endpoint="https://mlvoca.com/api/generate",
        auth_header="",
        auth_prefix="",
        rate_limit="unlimited",
        models=[
            Model("tinyllama",        "ğŸ†“ TinyLlama",            ["normal"]),
            Model("deepseek-r1:1.5b", "ğŸ†“ DeepSeek R1 1.5B ğŸ§ ", ["reasoning"]),
        ]
    ),

    # ==================== PUTER ====================
    # ğŸ†“ User-pays model â€” developer gratis, user pakai akun Puter sendiri
    # Docs: https://docs.puter.com/AI/chat/
    # Note: 500+ model tersedia, tidak perlu API key developer
    "puter": Provider(
        name="Puter",
        endpoint="https://api.puter.com/drivers/call",
        rate_limit="Free Tier (Puter.com) â€” User-Pays",
        models=[
            # â”€â”€ OpenAI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("gpt-5-nano",  "ğŸ†“ GPT-5 Nano ğŸ‘ï¸â­",  ["normal"], 128000, vision=True, tools=True),
            Model("gpt-5-mini",  "ğŸ†“ GPT-5 Mini ğŸ‘ï¸â­",  ["normal"], 128000, vision=True, tools=True),
            Model("gpt-4.1-nano","ğŸ†“ GPT-4.1 Nano â­",   ["normal"], 128000, tools=True),

            # â”€â”€ Anthropic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("claude-sonnet-4-5","ğŸ†“ Claude Sonnet 4.5 ğŸ”¥ğŸ§ ", ["normal", "reasoning"], 200000),
            Model("claude-3-5-sonnet","ğŸ†“ Claude 3.5 Sonnet ğŸ§ ",   ["normal", "reasoning"], 200000),

            # â”€â”€ Google â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("google/gemini-2.5-flash",   "ğŸ†“ Gemini 2.5 Flash ğŸ§ â­",    ["normal", "reasoning"], 1048576, tools=True),
            Model("google/gemini-2.5-pro",     "ğŸ†“ Gemini 2.5 Pro ğŸ”¥ğŸ§ â­",   ["normal", "reasoning"], 1048576, tools=True),
            Model("gemini-2.5-flash-lite",     "ğŸ†“ Gemini 2.5 Flash Lite â­",  ["normal"],              1048576, tools=True),

            # â”€â”€ DeepSeek â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("deepseek/deepseek-r1",   "ğŸ†“ DeepSeek R1 ğŸ§ ",  ["reasoning"], 128000),
            Model("deepseek/deepseek-chat", "ğŸ†“ DeepSeek V3 â­",  ["normal"],    128000, tools=True),

            # â”€â”€ xAI Grok â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("x-ai/grok-4-1-fast", "ğŸ†“ Grok 4.1 Fast ğŸ”¥â­", ["normal"], 131072, tools=True),
            Model("x-ai/grok-4-1-mini", "ğŸ†“ Grok 4.1 Mini â­",   ["normal"], 131072, tools=True),

            # â”€â”€ Meta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("meta-llama/llama-3.3-70b-instruct", "ğŸ†“ Llama 3.3 70B â­", ["normal"], 131072, tools=True),

            # â”€â”€ Perplexity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            Model("perplexity/sonar",     "ğŸ†“ Perplexity Sonar ğŸ”",       ["search"], 128000),
            Model("perplexity/sonar-pro", "ğŸ†“ Perplexity Sonar Pro ğŸ”¥ğŸ”", ["search"], 200000),
        ]
    ),
}

# ============================================================
# SEARCH PROVIDERS
# ============================================================

SEARCH_PROVIDERS = {
    "duckduckgo": {
        "name": "DuckDuckGo",
        "type": "library",
        "rate_limit": "unlimited",
        "requires_key": False,
    },
    "tavily": {
        "name": "Tavily",
        "endpoint": "https://api.tavily.com/search",
        "rate_limit": "1000/month",
        "requires_key": True,
    },
    "brave": {
        "name": "Brave",
        "endpoint": "https://api.search.brave.com/res/v1/web/search",
        "rate_limit": "2000/month",
        "requires_key": True,
    },
    "serper": {
        "name": "Serper",
        "endpoint": "https://google.serper.dev/search",
        "rate_limit": "2500 one-time",
        "requires_key": True,
    },
    "jina": {
        "name": "Jina",
        "endpoint": "https://s.jina.ai/{query}",
        "rate_limit": "rate limited",
        "requires_key": False,
    },
}

# ============================================================
# FALLBACK CHAINS â€” Updated with verified model IDs
# ============================================================

FALLBACK_CHAINS = {
    "normal": [
        ("groq",        "llama-3.3-70b-versatile"),
        ("groq",        "llama-3.1-8b-instant"),
        ("mistral",     "mistral-small-latest"),
        ("cerebras",    "llama3.1-8b"),
        ("nvidia",      "meta/llama-3.3-70b-instruct"),
        ("nvidia",      "deepseek-ai/deepseek-v3.2"),
        ("sambanova",   "Meta-Llama-3.3-70B-Instruct"),
        ("sambanova",   "DeepSeek-V3.2"),
        ("openrouter",  "openrouter/free"),
        ("openrouter",  "meta-llama/llama-3.3-70b-instruct:free"),
        ("openrouter",  "deepseek/deepseek-chat-v3-0324:free"),
        ("cloudflare",  "@cf/meta/llama-3.3-70b-instruct-fp8-fast"),
        ("cloudflare",  "@cf/meta/llama-3.1-8b-instruct"),
        ("routeway",    "llama-3.3-70b-instruct:free"),
        ("pollinations","openai"),
        ("puter",       "gpt-5-mini"),
    ],
    "reasoning": [
        ("groq",        "openai/gpt-oss-120b"),
        ("groq",        "qwen/qwen3-32b"),
        ("cerebras",    "gpt-oss-120b"),
        ("cerebras",    "zai-glm-4.7"),
        ("nvidia",      "nvidia/llama-3.1-nemotron-ultra-253b-v1"),
        ("nvidia",      "nvidia/llama-3.3-nemotron-super-49b-v1"),
        ("nvidia",      "deepseek-ai/deepseek-r1-distill-qwen-32b"),
        ("sambanova",   "DeepSeek-R1-0528"),
        ("sambanova",   "Qwen3-235B"),
        ("openrouter",  "openrouter/free"),
        ("openrouter",  "openai/gpt-oss-120b:free"),
        ("openrouter",  "deepseek/deepseek-r1:free"),
        ("openrouter",  "qwen/qwen3-coder:free"),
        ("openrouter",  "stepfun/step-3.5-flash:free"),
        ("cloudflare",  "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b"),
        ("cloudflare",  "@cf/qwen/qwq-32b"),
        ("routeway",    "deepseek-r1:free"),
        ("pollinations","perplexity-reasoning"),
    ],
    "search": [
        ("duckduckgo",  None),
        ("tavily",      None),
        ("brave",       None),
        ("serper",      None),
        ("jina",        None),
    ],
    "vision": [
        ("groq",        "meta-llama/llama-4-maverick-17b-128e-instruct"),
        ("groq",        "meta-llama/llama-4-scout-17b-16e-instruct"),
        ("nvidia",      "meta/llama-4-maverick-17b-128e-instruct"),
        ("nvidia",      "moonshotai/kimi-k2.5"),
        ("sambanova",   "Llama-4-Maverick-17B-128E-Instruct"),
        ("openrouter",  "meta-llama/llama-4-maverick:free"),
        ("openrouter",  "moonshotai/kimi-vl-a3b-thinking:free"),
        ("cloudflare",  "@cf/meta/llama-3.2-11b-vision-instruct"),
        ("puter",       "gpt-5-nano"),
        ("pollinations","openai-fast"),
    ],
}

# ============================================================
# LAVALINK NODES (Music Servers)
# ============================================================

LAVALINK_NODES = [
    {
        "identifier": "Serenetia-V4",
        "host":        os.getenv("LAVALINK_HOST",     "lavalinkv4.serenetia.com"),
        "port":        int(os.getenv("LAVALINK_PORT", "443")),
        "password":    os.getenv("LAVALINK_PASSWORD", "https://dsc.gg/ajidevserver"),
        "secure":      os.getenv("LAVALINK_SECURE",   "true").lower() == "true",
        "heartbeat":   30,
        "retries":     3,
    }
]

GENIUS_TOKEN = os.getenv("GENIUS_API_KEY")

# ============================================================
# HELPER FUNCTIONS
# ============================================================

def get_provider(name: str) -> Optional[Provider]:
    return PROVIDERS.get(name.lower())

def get_model(provider_name: str, model_id: str) -> Optional[Model]:
    provider = get_provider(provider_name)
    if provider:
        for model in provider.models:
            if model.id == model_id:
                return model
    return None

def get_models_by_mode(mode: str) -> List[tuple]:
    results = []
    for provider_name, provider in PROVIDERS.items():
        for model in provider.models:
            if mode in model.modes:
                results.append((provider_name, model))
    return results

def get_api_key(provider_name: str) -> Optional[str]:
    return API_KEYS.get(provider_name.lower())

def is_provider_available(provider_name: str) -> bool:
    provider = get_provider(provider_name)
    if not provider:
        return False
    if provider_name in ["mlvoca", "puter"]:
        return True
    if provider_name == "pollinations":
        return True
    return bool(get_api_key(provider_name))

def list_available_providers() -> List[str]:
    return [name for name in PROVIDERS.keys() if is_provider_available(name)]

def get_tools_capable_models() -> List[tuple]:
    """Return semua model yang support tool calling."""
    return [
        (provider_name, model)
        for provider_name, provider in PROVIDERS.items()
        for model in provider.models
        if model.tools
    ]

def get_vision_capable_models() -> List[tuple]:
    """Return semua model yang support vision/image."""
    return [
        (provider_name, model)
        for provider_name, provider in PROVIDERS.items()
        for model in provider.models
        if model.vision
    ]

def get_free_models() -> List[tuple]:
    """Return semua model gratis (ğŸ†“ atau âš ï¸)."""
    return [
        (provider_name, model)
        for provider_name, provider in PROVIDERS.items()
        for model in provider.models
        if "ğŸ†“" in model.name or "âš ï¸" in model.name
    ]

def get_premium_models() -> List[tuple]:
    """Return semua model premium (ğŸ’)."""
    return [
        (provider_name, model)
        for provider_name, provider in PROVIDERS.items()
        for model in provider.models
        if "ğŸ’" in model.name
    ]
